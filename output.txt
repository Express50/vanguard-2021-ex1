$ python train.py
ℹ Using CPU

=========================== Initializing pipeline ===========================
Set up nlp object from config
Loading corpus from path: data\dev_1000_clean.spacy
Loading corpus from path: data\train_1000_clean.spacy
Pipeline: ['tok2vec', 'ner']
Loading lookups from spacy-lookups-data: ['lexeme_norm']
Added vocab lookups: lexeme_norm
Created vocabulary
Finished initializing nlp object
Initialized pipeline components: ['tok2vec', 'ner']
✔ Initialized pipeline

============================= Training pipeline =============================
Loading corpus from path: data\dev_1000_clean.spacy
Loading corpus from path: data\train_1000_clean.spacy
Removed existing output directory: training\model-last
ℹ Pipeline: ['tok2vec', 'ner']
ℹ Initial learn rate: 0.001
E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE
---  ------  ------------  --------  ------  ------  ------  ------
  0       0          0.00     44.79    0.00    0.00    0.00    0.00
  0      50         23.32   1111.54    0.00    0.00    0.00    0.00
  0     100         24.35    303.90    0.00    0.00    0.00    0.00
  0     150         22.47    293.69    0.00    0.00    0.00    0.00
  0     200         23.97    309.80    0.00    0.00    0.00    0.00
  0     250         27.84    337.56    0.00    0.00    0.00    0.00
  0     300         50.26    359.26    1.04    8.78    0.55    0.01
  0     350         35.79    362.75    0.08    7.69    0.04    0.00
  0     400         38.78    379.30    0.23    1.38    0.13    0.00
  0     450         34.52    376.11    0.25    4.92    0.13    0.00
  0     500         38.95    395.39    0.17    3.92    0.08    0.00
  0     550        100.43    450.98    1.35    5.83    0.76    0.01
  1     600        463.87    553.14    0.88    7.48    0.47    0.01
  1     650         65.84    424.23    1.56    4.67    0.93    0.02
  1     700       1051.90    525.18    1.81    4.27    1.15    0.02
  1     750        135.48    541.10    2.05    4.17    1.36    0.02
  1     800        115.27    503.79    1.85    5.62    1.10    0.02
  1     850        170.30    574.63    1.86    4.98    1.15    0.02
  1     900        280.26    520.45    2.33    4.86    1.53    0.02
  2     950        714.76    622.50    3.59    5.47    2.68    0.04
  2    1000        720.22    627.64    1.84    3.62    1.23    0.02
  2    1050       1078.41    780.75    2.37    5.27    1.53    0.02
  2    1100        538.29    689.20    3.41    5.56    2.46    0.03
  2    1150        235.21    677.78    2.00    4.62    1.27    0.02
  3    1200        415.19    734.24    3.28    5.75    2.29    0.03
  3    1250        497.53    779.87    3.99    5.46    3.14    0.04
  3    1300        958.59    862.42    2.82    5.41    1.91    0.03
  3    1350        528.37    833.64    2.87    4.41    2.12    0.03
  4    1400        668.74    917.28    2.58    4.66    1.78    0.03
  4    1450        468.82    949.55    3.59    5.62    2.63    0.04
  4    1500        770.23    998.26    3.30    5.16    2.42    0.03
  5    1550        641.93   1004.57    3.53    5.03    2.72    0.04
  5    1600        447.39   1039.14    3.25    5.33    2.34    0.03
  5    1650        804.95   1125.67    4.33    6.59    3.23    0.04
  6    1700        314.94   1066.86    3.32    4.78    2.55    0.03
  6    1750        616.82   1258.52    4.52    5.82    3.70    0.05
  6    1800        571.43   1289.09    4.11    5.41    3.31    0.04
  7    1850        527.46   1249.44    3.80    4.81    3.14    0.04
  7    1900        959.57   1510.10    3.81    5.57    2.89    0.04
  8    1950        822.25   1370.31    3.43    5.06    2.59    0.03
  8    2000        797.75   1594.55    3.21    5.12    2.34    0.03
  9    2050        779.27   1507.47    3.52    4.51    2.89    0.04
  9    2100        518.58   1610.08    4.13    5.71    3.23    0.04
 10    2150       1061.90   1826.59    3.43    4.91    2.63    0.03
 11    2200        690.04   1759.93    4.39    6.06    3.44    0.04
 11    2250        619.78   1824.63    3.88    5.29    3.06    0.04
 12    2300       1305.45   2143.15    3.85    5.59    2.93    0.04